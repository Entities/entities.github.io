---
layout: post
title: Installment 01 - Kick-Off!
---

In this post we provide strong evidence that 
auto-encoders have very poor creative skills. We develop multiple models, 
starting from a standard convolutional auto-encoder up to a very sophisticated 
36-layer ResNet and run experiments that shattered our hopes of ever generating somewhat 
"life-like" images let alone analysing the effect of captions. 

While this introduction might, at first sight, 
seem hugely pessimistic we we're able to gather important 
intelligence that will help us throughout this project, 
we also pinpoint the main flaw in our model and propose 
an alternative that we will explore in the following posts.

##### The Project in One Sentence

We are given captions associated to images where the middle region has been cropped, the goal 
is to regenerate these images.

![_config.yml]({{ site.baseurl }}/images/imagecaptionex.png)

The problem is ill-posed because we don't care about an exact replica of the images;
rather, we would like clear illustrations, coherent with their tags and the world as we're 
used to see it (e.g. no wings on an airplane).

Before thinking about coherence between tags and images, one must first be able to generate
decent quality pictures, therefore this post and probably the next one will be dedicated to 
this task.
 
##### A First Model...

![_config.yml]({{ site.baseurl }}/images/autoencoder.png)

<sup>**Fig. 1. Visual representation of our first model; a four-layer deep 
convolutional autoencoder with 1024 units fully-connected layer encoder.**</sup>

An auto-encoder seemed like a natural choice for me to starts with, in theory, it has
(almost) everything you would need: An encoder network that synthesizes the information in
a compact form that is decrypted by the decoder to generate a plausible middle region.
 
However, it has a big flaw, which resides in the way it addresses the problem by itself:
by optimizing the mean squared error it learns to detect irregular patterns pixel-wise 
which makes it incredible at denoising [1] but terrible at creating since the latter
requires a more global understanding of the picture and what it is depicting.

The following figure display a few images generated by our most basic model with 
different "degree" of regularization.


 




















